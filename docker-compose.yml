services:
  jirascope-dev:
    build:
      context: .
      target: dev
    ports:
      - "8000:8000"
    volumes:
      - .:/app
      - ./data:/app/data
      - ./reports:/app/reports
      - ./config:/app/config
    environment:
      - JIRA_MCP_ENDPOINT=${JIRA_MCP_ENDPOINT:-}
      - CLAUDE_API_KEY=${CLAUDE_API_KEY:-}
      - LMSTUDIO_ENDPOINT=http://lmstudio:1234/v1
      - QDRANT_URL=http://qdrant:6333
      - PYTHONPATH=/app/src
    depends_on:
      - qdrant
    stdin_open: true
    tty: true
    command: ["python", "-m", "uvicorn", "web.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

  jirascope-web:
    build:
      context: .
      target: prod
    ports:
      - "8080:8000"
    environment:
      - JIRA_MCP_ENDPOINT=${JIRA_MCP_ENDPOINT:-}
      - CLAUDE_API_KEY=${CLAUDE_API_KEY:-}
      - LMSTUDIO_ENDPOINT=http://lmstudio:1234/v1
      - QDRANT_URL=http://qdrant:6333
    depends_on:
      - qdrant
    command: ["python", "-m", "uvicorn", "web.main:app", "--host", "0.0.0.0", "--port", "8000"]

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage

  # Optional: LM Studio replacement (if needed)
  # embedding-service:
  #   image: huggingface/text-embeddings-inference:latest
  #   ports:
  #     - "1234:80"
  #   environment:
  #     - MODEL_ID=bge-large-en-v1.5-gguf/bge-large-en-v1.5-q8_0.gguf
  #   volumes:
  #     - ./models:/data

volumes:
  qdrant_data:
